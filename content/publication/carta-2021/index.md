---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: 'Catastrophic Forgetting in Deep Graph Networks: An Introductory Benchmark
  for Graph Classification'
subtitle: ''
summary: ''
authors:
- Antonio Carta
- Andrea Cossu
- Federico Errica
- Davide Bacciu
tags:
- '"Computer Science - Artificial Intelligence"'
- '"Computer Science - Machine Learning"'
- '"I.2.6"'
categories: [continual-learning]
date: '2021-01-01'
lastmod: 2021-03-24T15:27:12+01:00
featured: false
draft: false


# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-03-24T14:27:11.992466Z'
publication_types:
- '2'
abstract: In this work, we study the phenomenon of catastrophic forgetting in the
  graph representation learning scenario. The primary objective of the analysis is
  to understand whether classical continual learning techniques for flat and sequential
  data have a tangible impact on performances when applied to graph data. To do so,
  we experiment with a structure-agnostic model and a deep graph network in a robust
  and controlled environment on three different datasets. The benchmark is complemented
  by an investigation on the effect of structure-preserving regularization techniques
  on catastrophic forgetting. We find that replay is the most effective strategy in
  so far, which also benefits the most from the use of regularization. Our findings
  suggest interesting future research at the intersection of the continual and graph
  representation learning fields. Finally, we provide researchers with a flexible
  software framework to reproduce our results and carry out further experiments.
publication: '*The 2021 Web Conference (WWW) Workshop on Graph Benchmarks Learning
  (GLB)*'
url_pdf: http://arxiv.org/abs/2103.11750
url_code: https://github.com/diningphil/continual_learning_for_graphs
url_dataset:
url_poster:
url_project:
url_slides: https://www.slideserve.com/andcos/forgetting-in-deep-graph-networks
url_source:
url_video:
---
