@inproceedings{cossu2021a,
 abstract = {Continual Learning (CL) refers to a learning setup where data is non stationary and the model has to learn without forgetting existing knowledge. The study of CL for sequential patterns revolves around trained recurrent networks. In this work, instead, we introduce CL in the context of Echo State Networks (ESNs), where the recurrent component is kept fixed. We provide the first evaluation of catastrophic forgetting in ESNs and we highlight the benefits in using CL strategies which are not applicable to trained recurrent models. Our results confirm the ESN as a promising model for CL and open to its use in streaming scenarios.},
 archiveprefix = {arXiv},
 author = {Cossu, Andrea and Bacciu, Davide and Carta, Antonio and Gallicchio, Claudio and Lomonaco, Vincenzo},
 booktitle = {ESANN},
 copyright = {All rights reserved},
 eprint = {2105.07674},
 eprinttype = {arxiv},
 file = {/home/andrea/Zotero/storage/XWE5KCKZ/Cossu et al. - 2021 - Continual Learning with Echo State Networks.pdf;/home/andrea/Zotero/storage/PS3V6BK6/2105.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
 title = {Continual Learning with Echo State Networks},
 url = {http://arxiv.org/abs/2105.07674},
 urldate = {2021-05-28},
 year = {2021}
}

